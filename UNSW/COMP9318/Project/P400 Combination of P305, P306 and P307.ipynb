{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of P305, P306 and P307\n",
    "+ Hope this is the last model I build\n",
    "+ Based on distance-weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import some modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helper\n",
    "import submission\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vowel = {'AA': 0, 'AW': 1, 'AY': 2, 'ER': 3, 'EY': 4, 'IY': 5, 'OW': 6, 'OY': 7, 'UW': 8, 'AE': 9, 'AH': 10, 'AO': 11, 'EH': 12, 'IH': 13, 'UH': 14}\n",
    "consonant = {'AA': 0, 'AW': 1, 'AY': 2, 'ER': 3, 'EY': 4, 'IY': 5, 'OW': 6, 'OY': 7, 'UW': 8, 'AE': 9, 'AH': 10, 'AO': 11, 'EH': 12, 'IH': 13, 'UH': 14, 'P': 15, 'B': 16, 'CH': 17, 'D': 18, 'DH': 19, 'F': 20, 'G': 21, 'HH': 22, 'JH': 23, 'K': 24, 'L': 25, 'M': 26, 'N': 27, 'NG': 28, 'R': 29, 'S': 30, 'SH': 31, 'T': 32, 'TH': 33, 'V': 34, 'W': 35, 'Y': 36, 'Z': 37, 'ZH': 38}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 'SOBRIQUET:S OW1 B R AH0 K EY2' --> 'SOBRIQUET', ['S', 'OW1', 'B', 'R', 'AH0', 'K', 'EY2']\n",
    "def split_to_list(curr_row):\n",
    "    word = curr_row[:curr_row.index(':')]\n",
    "    splitted_list = curr_row[curr_row.index(':') + 1 : ].split(' ')\n",
    "    return word, splitted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SOBRIQUET', ['S', 'OW1', 'B', 'R', 'AH0', 'K', 'EY2'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test:\n",
    "split_to_list('SOBRIQUET:S OW1 B R AH0 K EY2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ['S', 'OW1', 'B', 'R', 'AH0', 'K', 'EY2'] --> ['S', 'OW', 'B', 'R', 'AH', 'K', 'EY'], 1\n",
    "def check(splitted_list):\n",
    "    count = 0\n",
    "    target = 0\n",
    "    removed_stress = []\n",
    "    for item in splitted_list[:]:\n",
    "        try: # vowel\n",
    "            curr = int(item[-1]) \n",
    "            removed_stress.append(item[:-1])\n",
    "            count += 1\n",
    "            if curr == 1:\n",
    "                target = count\n",
    "        except: # consonant\n",
    "            removed_stress.append(item)\n",
    "    return removed_stress, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S', 'OW', 'B', 'R', 'AH', 'K', 'EY'], 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test:\n",
    "check(['S', 'OW1', 'B', 'R', 'AH0', 'K', 'EY2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This can not be integrated with check() for that we need to use it for several times\n",
    "## ['S', 'OW', 'B', 'R', 'AH', 'K', 'EY'] --> 3\n",
    "def count_vowel(removed_stress, vowel):\n",
    "    count = 0\n",
    "    for item in removed_stress[:]:\n",
    "        if item in vowel:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test:\n",
    "count_vowel(['S', 'OW', 'B', 'R', 'AH', 'K', 'EY'], vowel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Singular filter: \n",
    "def singular_filter(word, removed_stress):\n",
    "    \n",
    "    ## If the word has no more than 3 letters we do not refine it(to avoid abbrevation)\n",
    "    if len(word) <= 3:\n",
    "        return word, removed_stress\n",
    "    \n",
    "    sub_string1 = word[-2: ]\n",
    "    sub_string2 = word[-3: ]\n",
    "    sub_string3 = word[-6: ]    \n",
    "    sub_string4 = word[-4: ]\n",
    "    \n",
    "    pattern1 = re.compile('[BCDFGHJKLMNOPQRTVWYZ]{1}S$')\n",
    "    pattern2 = re.compile('XS$')\n",
    "    # For CDFGHKLPWRTWYZ --> remove 'S' from word, remove 'S/Z' from removed_stress\n",
    "    if re.match(pattern1, sub_string1):\n",
    "        return word[:-1], removed_stress[:-1]\n",
    "    # For X --> remove 'S' from word, remove 'IH Z' from removed_stress\n",
    "    if re.match(pattern2, sub_string1):\n",
    "        return word[:-1], removed_stress[:-2]\n",
    "    \n",
    "    # -ES\n",
    "    pattern3 = re.compile('[ABDEFJKLMNOPQRTUWY]{1}ES$')\n",
    "    pattern4 = re.compile('IES$')\n",
    "    pattern5 = re.compile('HES$')\n",
    "    pattern55 = re.compile('ZZES$|SSES$')\n",
    "    pattern6 = re.compile('[CGSXZ]{1}ES$')\n",
    "    pattern7 = re.compile('SELVES$')\n",
    "    pattern8 = re.compile('IVES$')\n",
    "    pattern9 = re.compile('VES$')\n",
    "    \n",
    "    if re.match(pattern3, sub_string2): # ES --> E\n",
    "        return word[:-1], removed_stress[:-1]\n",
    "    if re.match(pattern4, sub_string2): # IES --> Y\n",
    "        word = word[:-3] + 'Y'\n",
    "        return word, removed_stress[:-1]\n",
    "    if re.match(pattern5, sub_string2):\n",
    "        return word[:-2], removed_stress[:-2]\n",
    "    if re.match(pattern55, sub_string4):\n",
    "        return word[:-2], removed_stress[:-2]\n",
    "    if re.match(pattern6, sub_string2):\n",
    "        return word[:-1], removed_stress[:-2]\n",
    "    if re.match(pattern7, sub_string3):\n",
    "        word = word[:-6] + 'SELF'\n",
    "        removed_stress.pop()\n",
    "        removed_stress.pop()\n",
    "        removed_stress.append('F')\n",
    "        return word, removed_stress\n",
    "    if re.match(pattern8, sub_string4) and (removed_stress[-3:] == ['AY', 'V', 'Z']):\n",
    "        word = word[:-3] + 'FE'\n",
    "        removed_stress.pop()\n",
    "        removed_stress.pop()\n",
    "        removed_stress.append('F')\n",
    "        return word, removed_stress\n",
    "    if re.match(pattern9, sub_string2):\n",
    "        return word[:-1], removed_stress[:-1]\n",
    "    \n",
    "    return word, removed_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRIGLYCERIDE', ['T', 'R', 'AY', 'G', 'L', 'IH', 'S', 'ER', 'AY', 'D'])\n",
      "('COUNTESS', ['K', 'AW', 'N', 'T', 'AH', 'S'])\n",
      "('SECURE', ['S', 'IH', 'K', 'Y', 'UH', 'R'])\n",
      "('YOURSELF', ['Y', 'UH', 'R', 'S', 'EH', 'L', 'F'])\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "print(singular_filter('TRIGLYCERIDES',['T','R','AY', 'G', 'L', 'IH', 'S', 'ER', 'AY', 'D', 'Z']))\n",
    "print(singular_filter('COUNTESSES', ['K', 'AW', 'N', 'T', 'AH', 'S', 'IH', 'Z']))\n",
    "print(singular_filter('SECURES',['S', 'IH', 'K', 'Y', 'UH', 'R', 'Z']))\n",
    "print(singular_filter('YOURSELVES',['Y','UH', 'R', 'S', 'EH', 'L', 'V', 'Z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove some neutral suffixes\n",
    "def neutral_filter1(word, removed_stress):\n",
    "    pattern1 = re.compile('ABLY$')\n",
    "    if re.search(pattern1, word):\n",
    "        word = word[:-1] + 'E'\n",
    "        return word, removed_stress[:-1]\n",
    "    \n",
    "    pattern2 = re.compile('LL[YI]{1}$|LLED$|SSED$|FFED$')\n",
    "    if re.search(pattern2, word):\n",
    "        return word[:-2], removed_stress[:-1]\n",
    "    \n",
    "    pattern3 = re.compile('L[YI]{1}$')\n",
    "    if re.search(pattern3, word) and removed_stress[-2:] == ['L', 'IY']:\n",
    "        return word[:-2], removed_stress[:-2]\n",
    "    \n",
    "    pattern4 = re.compile('DDED$|TTED$')\n",
    "    if re.search(pattern4, word):\n",
    "        return word[:-3], removed_stress[:-2]\n",
    "    \n",
    "    pattern5 = re.compile('[AEIOU]{1}[DFT]{1}ED$')\n",
    "    if re.search(pattern5, word):\n",
    "        return word[:-1], removed_stress[:-2]\n",
    "    \n",
    "    pattern6 = re.compile('[AEIOU]{1}[KMNS]{1}ED$|[IU]{1}RED$|IBED$')\n",
    "    if re.search(pattern6, word):\n",
    "        return word[:-1], removed_stress[:-1]\n",
    "    \n",
    "    pattern7 = re.compile('BBED$|GGED$|MMED$|NNED$|PPED$|RRED$')\n",
    "    if re.search(pattern7, word):\n",
    "        return word[:-3], removed_stress[:-1]\n",
    "    \n",
    "    pattern10 = re.compile('[BHKMNOPSWXY]{1}ED$')\n",
    "    if re.search(pattern10, word):\n",
    "        return word[:-2], removed_stress[:-1]\n",
    "    \n",
    "    pattern11 = re.compile('IED$')\n",
    "    if re.search(pattern11, word):\n",
    "        word = word[:-3] + 'Y'\n",
    "        return word, removed_stress[:-1]\n",
    "    \n",
    "    pattern12 = re.compile('[CGLUVZ]{1}ED$')\n",
    "    if re.search(pattern12, word):\n",
    "        return word[:-1], removed_stress[:-1]\n",
    "    \n",
    "    pattern13 = re.compile('[DFTR]{1}ED$')\n",
    "    if re.search(pattern13, word):\n",
    "        return word[:-2], removed_stress[:-2]\n",
    "    \n",
    "    pattern14 = re.compile('ISM$')\n",
    "    if re.search(pattern14, word):\n",
    "        return word[:-3], removed_stress[:-4]    \n",
    "    \n",
    "    pattern15 = re.compile('FUL$')\n",
    "    if re.search(pattern15, word):\n",
    "        return word[:-3], removed_stress[:-3]  \n",
    "    \n",
    "    pattern16 = re.compile('NESS$') # remove 'NESS', remove 'N AH0 S'\n",
    "    if re.search(pattern16, word):\n",
    "        return word[:-4], removed_stress[:-3]\n",
    "    \n",
    "    pattern17 = re.compile('[A-HK-Z]ING$') # JING is omitted (\"BEIJING\")\n",
    "    if re.search(pattern17, word):\n",
    "        return word[:-3], removed_stress[:-2]\n",
    "    \n",
    "    return word, removed_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_filter(word, removed_stress, vowel):\n",
    "    \n",
    "    word, removed_stress = singular_filter(word, removed_stress)\n",
    "    if len(word) == 0 or len(removed_stress) == 0: \n",
    "        return 1, [1]\n",
    "    \n",
    "    word, removed_stress = neutral_filter1(word, removed_stress)\n",
    "    if len(word) == 0 or len(removed_stress) == 0: \n",
    "        return 1, [1]\n",
    "    \n",
    "    if count_vowel(removed_stress, vowel) == 0:\n",
    "        return 1, [1]\n",
    "    \n",
    "    return word, removed_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MUSCL', ['M', 'AH', 'S', 'AH', 'L'])\n",
      "('BOTO', ['B', 'OW', 'T', 'OW'])\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "print(combined_filter('MUSCLING',['M', 'AH', 'S', 'AH', 'L', 'IH', 'NG'], vowel))\n",
    "print(combined_filter('BOTOS',['B', 'OW', 'T', 'OW', 'Z'], vowel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test\n",
    "# RemovedStress = ['N', 'AA', 'N', 'P', 'OY', 'Z', 'AH', 'N', 'AH', 'S']\n",
    "# vowels = [0, 7, 10, 10]\n",
    "# vowel_positions = [1, 4, 6, 8]\n",
    "# structure = CVCCVCVCVC\n",
    "# VowelMap = [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "# ConsonantMap = [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
    "# VectorMap = [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "def get_structure_and_vowels(removed_stress, vowel, consonant):\n",
    "    structure = ''\n",
    "    num_vowels = 0\n",
    "    count = 0\n",
    "    vowels = []\n",
    "    vowel_positions = []\n",
    "    VowelMap = []\n",
    "    ConsonantMap = []\n",
    "    VectorMap = [0] * 39\n",
    "    for item in removed_stress[:]:\n",
    "        vowel_index = consonant.get(item)\n",
    "        VectorMap[vowel_index] = 1\n",
    "        if item in vowel:\n",
    "            structure += 'V'\n",
    "            vowels.append(vowel_index)\n",
    "            VowelMap.append(1)\n",
    "            ConsonantMap.append(0)\n",
    "            vowel_positions.append(count)\n",
    "            num_vowels += 1\n",
    "            count += 1\n",
    "        else:\n",
    "            VowelMap.append(0)\n",
    "            ConsonantMap.append(1)\n",
    "            structure += 'C'\n",
    "            count += 1\n",
    "            \n",
    "    if count < 15:\n",
    "        VowelMap += [0] * (15 - count)\n",
    "        ConsonantMap += [0] * (15 - count)\n",
    "    return vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 10, 10]\n",
      "[1, 4, 6, 8]\n",
      "CVCCVCVCVC\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "-----\n",
      "[1, 10, 13]\n",
      "[1, 4, 6]\n",
      "CVCCVCVC\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "-----\n",
      "[2, 3]\n",
      "[1, 3]\n",
      "CVCV\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(['N', 'AA', 'N', 'P', 'OY', 'Z', 'AH', 'N', 'AH', 'S'], vowel, consonant)\n",
    "output = [vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap]\n",
    "for item in output[:]:\n",
    "    print(item)\n",
    "print('-----')\n",
    "vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(['K', 'AW', 'N', 'T', 'AH', 'S', 'IH', 'Z'], vowel, consonant)\n",
    "output = [vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap]\n",
    "for item in output[:]:\n",
    "    print(item)\n",
    "print('-----')\n",
    "vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(['L', 'AY', 'S', 'ER',], vowel, consonant)\n",
    "output = [vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap]\n",
    "for item in output[:]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prefix_and_suffix(vowel_positions, removed_stress, consonant):\n",
    "    result = []\n",
    "    for curr_position in vowel_positions[:]:\n",
    "        if curr_position == 0: # no prefixes\n",
    "            prefix1 = 39\n",
    "        else:\n",
    "            prefix1 = consonant.get(removed_stress[curr_position - 1])\n",
    "        result.append(prefix1)\n",
    "        try:\n",
    "            suffix1 = consonant.get(removed_stress[curr_position + 1])\n",
    "        except:\n",
    "            suffix1 = 39\n",
    "        result.append(suffix1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 27, 15, 37, 37, 27, 27, 30]\n",
      "[24, 27, 32, 30, 30, 37]\n",
      "[25, 30, 30, 39]\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "print(get_prefix_and_suffix([1,4,6,8], ['N', 'AA', 'N', 'P', 'OY', 'Z', 'AH', 'N', 'AH', 'S'], consonant))\n",
    "print(get_prefix_and_suffix([1,4,6], ['K', 'AW', 'N', 'T', 'AH', 'S', 'IH', 'Z'], consonant))\n",
    "print(get_prefix_and_suffix([1,3], ['L', 'AY', 'S', 'ER'], consonant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_structure_vowel2(vowel_positions, removed_stress):\n",
    "    split_result = []\n",
    "    if vowel_positions[1] - vowel_positions[0] > 1: \n",
    "        split_result.append(' '.join(removed_stress[:vowel_positions[1] - 1]))\n",
    "        split_result.append(' '.join(removed_stress[vowel_positions[1] - 1 : ]))\n",
    "    else:\n",
    "        split_result.append(' '.join(removed_stress[:vowel_positions[0] + 1]))\n",
    "        split_result.append(' '.join(removed_stress[vowel_positions[0] + 1 : ]))\n",
    "    return split_result\n",
    "def split_structure_vowel3(vowel_positions, removed_stress):\n",
    "    if vowel_positions[1] - vowel_positions[0] > 1: # CVCCCVXXXX\n",
    "        part1 = removed_stress[:vowel_positions[1] - 1]\n",
    "        removed_stress = removed_stress[vowel_positions[1] - 1 : ]\n",
    "        \n",
    "    else: # CVVXXXX\n",
    "        part1 = removed_stress[:vowel_positions[0] + 1]\n",
    "        removed_stress = removed_stress[vowel_positions[0] + 1 : ]\n",
    "    \n",
    "    vowel_positions = [vowel_positions[1] - len(part1), vowel_positions[2] - len(part1)]\n",
    "    sub_split_result = split_structure_vowel2(vowel_positions, removed_stress)\n",
    "    split_result = [' '.join(part1)]\n",
    "    split_result.extend(sub_split_result)\n",
    "    return split_result\n",
    "def split_structure_vowel4(vowel_positions, removed_stress):\n",
    "    if vowel_positions[1] - vowel_positions[0] > 1: # CVCCCVXXXX\n",
    "        part1 = removed_stress[:vowel_positions[1] - 1]\n",
    "        removed_stress = removed_stress[vowel_positions[1] - 1 : ]\n",
    "        \n",
    "    else: # CVVXXXX\n",
    "        part1 = removed_stress[:vowel_positions[0] + 1]\n",
    "        removed_stress = removed_stress[vowel_positions[0] + 1 : ]\n",
    "    \n",
    "    vowel_positions = [vowel_positions[1] - len(part1), vowel_positions[2] - len(part1), vowel_positions[3] - len(part1)]\n",
    "    sub_split_result = split_structure_vowel3(vowel_positions, removed_stress)\n",
    "    split_result = [' '.join(part1)]\n",
    "    split_result.extend(sub_split_result)\n",
    "    return split_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K R IH S P', 'N AH S']\n",
      "['HH Y UW', 'IY']\n",
      "['IY', 'EY N']\n",
      "['AY', 'AA', 'N IH K']\n",
      "['W EH L', 'TH IY', 'ER']\n",
      "['S IH K', 'W EH S', 'T ER', 'IH NG']\n",
      "['T R AE N S F', 'Y UW', 'ZH AH N']\n",
      "['AE B', 'S AH N T']\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "rs = ['K', 'R', 'IH', 'S', 'P', 'N', 'AH', 'S'] # CRISPNESS\n",
    "vp = [2,6]\n",
    "print(split_structure_vowel2(vp,rs))\n",
    "rs = ['HH', 'Y', 'UW', 'IY'] # HEWEY / HUIE\n",
    "vp = [2,3]\n",
    "print(split_structure_vowel2(vp,rs))\n",
    "rs = ['IY', 'EY', 'N'] # IAIN\n",
    "vp = [0,1]\n",
    "print(split_structure_vowel2(vp,rs)) \n",
    "vp = [0,1,3]\n",
    "rs = ['AY', 'AA', 'N', 'IH', 'K'] # IONIC\n",
    "print(split_structure_vowel3(vp,rs)) \n",
    "vp = [1,4,5]\n",
    "rs = ['W', 'EH', 'L', 'TH', 'IY', 'ER'] # WEALTHIER\n",
    "print(split_structure_vowel3(vp,rs))\n",
    "rs = ['S', 'IH', 'K', 'W', 'EH', 'S', 'T', 'ER', 'IH', 'NG'] # SEQUESTERING\n",
    "vp = [1,4,7,8]\n",
    "print(split_structure_vowel4(vp,rs))\n",
    "rs = ['T', 'R', 'AE', 'N', 'S', 'F', 'Y', 'UW', 'ZH', 'AH', 'N'] # TRANSFUSION\n",
    "vp = [2,7,9]\n",
    "print(split_structure_vowel3(vp,rs))\n",
    "rs = ['AE', 'B', 'S', 'AH', 'N', 'T'] # ABSENT\n",
    "vp = [0,3]\n",
    "print(split_structure_vowel2(vp,rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get splitted data and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_splitted_data(raw_data, vowel, consonant):\n",
    "    vowel2 = []\n",
    "    vowel3 = []\n",
    "    vowel4 = []\n",
    "    \n",
    "    for curr_row in raw_data[:]:\n",
    "        word, splitted_list = split_to_list(curr_row)\n",
    "        removed_stress, target = check(splitted_list)\n",
    "        word, removed_stress = combined_filter(word, removed_stress, vowel)\n",
    "        \n",
    "        if word == 1 or removed_stress == [1]:\n",
    "            continue\n",
    "        \n",
    "        num_vowel = count_vowel(removed_stress, vowel)\n",
    "        \n",
    "        if num_vowel <= 1:\n",
    "            continue\n",
    "        elif num_vowel == 2:\n",
    "            vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(removed_stress, vowel, consonant)\n",
    "            prefix_suffix = get_prefix_and_suffix(vowel_positions, removed_stress, consonant)\n",
    "            syllables = split_structure_vowel2(vowel_positions, removed_stress)\n",
    "            row_data = [target, word, vowels, prefix_suffix, VowelMap, ConsonantMap, VectorMap, syllables]\n",
    "            vowel2.append(row_data)\n",
    "        elif num_vowel == 3:\n",
    "            vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(removed_stress, vowel, consonant)\n",
    "            prefix_suffix = get_prefix_and_suffix(vowel_positions, removed_stress, consonant)\n",
    "            syllables = split_structure_vowel3(vowel_positions, removed_stress)\n",
    "            row_data = [target, word, vowels, prefix_suffix, VowelMap, ConsonantMap, VectorMap, syllables]\n",
    "            vowel3.append(row_data)\n",
    "        else:\n",
    "            vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(removed_stress, vowel, consonant)\n",
    "            prefix_suffix = get_prefix_and_suffix(vowel_positions, removed_stress, consonant)\n",
    "            syllables = split_structure_vowel4(vowel_positions, removed_stress)\n",
    "            row_data = [target, word, vowels, prefix_suffix, VowelMap, ConsonantMap, VectorMap, syllables]\n",
    "            vowel4.append(row_data)\n",
    "    \n",
    "    return vowel2, vowel3, vowel4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "18\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "raw_data = helper.read_data('asset/training_data.txt')\n",
    "vowel2, vowel3, vowel4 = get_splitted_data(raw_data[:100], vowel, consonant)\n",
    "print(len(vowel2))\n",
    "print(len(vowel3))\n",
    "print(len(vowel4))\n",
    "print(len(vowel2[0]))\n",
    "print(len(vowel3[0]))\n",
    "print(len(vowel4[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vowels_to_bin(Vowels, vowel):\n",
    "    result = []\n",
    "    for item in Vowels[:]:\n",
    "        curr = [0] * 15\n",
    "        curr[item] += 1\n",
    "        result.extend(curr)\n",
    "    return result\n",
    "def prefix_suffix_to_bin(PrefixSuffix, consonant):\n",
    "    result = []\n",
    "    for item in PrefixSuffix[:]:\n",
    "        curr = [0] * 40 # note \"39\" is for boundary\n",
    "        curr[item] += 1\n",
    "        result.extend(curr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_combination(Syllables):\n",
    "    combination = []\n",
    "    length = len(Syllables)\n",
    "    for curr_length in range(1,length + 1):\n",
    "        for start_position in range(length - curr_length + 1):\n",
    "            combination.insert(0, ' '.join(Syllables[start_position : start_position + curr_length]))\n",
    "    return combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N AY JH IH R IY AH N', 'JH IH R IY AH N', 'N AY JH IH R IY', 'R IY AH N', 'JH IH R IY', 'N AY JH IH', 'AH N', 'R IY', 'JH IH', 'N AY']\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "# Test\n",
    "Syls = ['N AY', 'JH IH', 'R IY', 'AH N']\n",
    "print(get_combination(Syls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df(data, vowel, consonant):\n",
    "    df = pd.DataFrame(data, columns=['Target', 'Word', 'Vowels','PrefixSuffix', 'VowelPosition', 'ConsonantPosition', 'Occurrence', 'Syllables'])\n",
    "    df['VowelsBin'] = df.Vowels.apply(vowels_to_bin, vowel = vowel)\n",
    "    df['PrefixSuffixBin'] = df.PrefixSuffix.apply(prefix_suffix_to_bin, consonant = consonant)\n",
    "    df['SyllableCombination'] = df.Syllables.apply(get_combination)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Test\n",
    "df2 = get_df(vowel2, vowel, consonant)\n",
    "df3 = get_df(vowel3, vowel, consonant)\n",
    "df4 = get_df(vowel4, vowel, consonant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Word</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>PrefixSuffix</th>\n",
       "      <th>VowelPosition</th>\n",
       "      <th>ConsonantPosition</th>\n",
       "      <th>Occurrence</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>VowelsBin</th>\n",
       "      <th>PrefixSuffixBin</th>\n",
       "      <th>SyllableCombination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CO</td>\n",
       "      <td>[6, 12]</td>\n",
       "      <td>[24, 12, 6, 39]</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[K OW, EH]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[K OW EH, EH, K OW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PURVIEW</td>\n",
       "      <td>[3, 8]</td>\n",
       "      <td>[15, 34, 36, 39]</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[P ER V, Y UW]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[P ER V Y UW, Y UW, P ER V]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target     Word   Vowels      PrefixSuffix  \\\n",
       "0       1       CO  [6, 12]   [24, 12, 6, 39]   \n",
       "1       1  PURVIEW   [3, 8]  [15, 34, 36, 39]   \n",
       "\n",
       "                                   VowelPosition  \\\n",
       "0  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               ConsonantPosition  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                          Occurrence       Syllables  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...      [K OW, EH]   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  [P ER V, Y UW]   \n",
       "\n",
       "                                           VowelsBin  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     PrefixSuffixBin  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "           SyllableCombination  \n",
       "0          [K OW EH, EH, K OW]  \n",
       "1  [P ER V Y UW, Y UW, P ER V]  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Word</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>PrefixSuffix</th>\n",
       "      <th>VowelPosition</th>\n",
       "      <th>ConsonantPosition</th>\n",
       "      <th>Occurrence</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>VowelsBin</th>\n",
       "      <th>PrefixSuffixBin</th>\n",
       "      <th>SyllableCombination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>DARIUS</td>\n",
       "      <td>[3, 2, 10]</td>\n",
       "      <td>[18, 2, 3, 10, 2, 30]</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[D ER, AY, AH S]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[D ER AY AH S, AY AH S, D ER AY, AH S, AY, D ER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSINGER</td>\n",
       "      <td>[12, 13, 3]</td>\n",
       "      <td>[39, 27, 30, 27, 23, 39]</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>[EH N, S IH N, JH ER]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[EH N S IH N JH ER, S IH N JH ER, EH N S IH N,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target      Word       Vowels              PrefixSuffix  \\\n",
       "0       2    DARIUS   [3, 2, 10]     [18, 2, 3, 10, 2, 30]   \n",
       "1       1  ENSINGER  [12, 13, 3]  [39, 27, 30, 27, 23, 39]   \n",
       "\n",
       "                                   VowelPosition  \\\n",
       "0  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               ConsonantPosition  \\\n",
       "0  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                          Occurrence              Syllables  \\\n",
       "0  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...       [D ER, AY, AH S]   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  [EH N, S IH N, JH ER]   \n",
       "\n",
       "                                           VowelsBin  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                     PrefixSuffixBin  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 SyllableCombination  \n",
       "0   [D ER AY AH S, AY AH S, D ER AY, AH S, AY, D ER]  \n",
       "1  [EH N S IH N JH ER, S IH N JH ER, EH N S IH N,...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3.PrefixSuffixBin[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Word</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>PrefixSuffix</th>\n",
       "      <th>VowelPosition</th>\n",
       "      <th>ConsonantPosition</th>\n",
       "      <th>Occurrence</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>VowelsBin</th>\n",
       "      <th>PrefixSuffixBin</th>\n",
       "      <th>SyllableCombination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NONPOISONOUS</td>\n",
       "      <td>[0, 7, 10, 10]</td>\n",
       "      <td>[27, 27, 15, 37, 37, 27, 27, 30]</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[N AA N, P OY, Z AH, N AH S]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[N AA N P OY Z AH N AH S, P OY Z AH N AH S, N ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LAVECCHIA</td>\n",
       "      <td>[0, 12, 5, 10]</td>\n",
       "      <td>[25, 34, 34, 24, 24, 10, 5, 39]</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[L AA, V EH, K IY, AH]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[L AA V EH K IY AH, V EH K IY AH, L AA V EH K ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          Word          Vowels                      PrefixSuffix  \\\n",
       "0       2  NONPOISONOUS  [0, 7, 10, 10]  [27, 27, 15, 37, 37, 27, 27, 30]   \n",
       "1       2     LAVECCHIA  [0, 12, 5, 10]   [25, 34, 34, 24, 24, 10, 5, 39]   \n",
       "\n",
       "                                   VowelPosition  \\\n",
       "0  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               ConsonantPosition  \\\n",
       "0  [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "1  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                          Occurrence  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "\n",
       "                      Syllables  \\\n",
       "0  [N AA N, P OY, Z AH, N AH S]   \n",
       "1        [L AA, V EH, K IY, AH]   \n",
       "\n",
       "                                           VowelsBin  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     PrefixSuffixBin  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 SyllableCombination  \n",
       "0  [N AA N P OY Z AH N AH S, P OY Z AH N AH S, N ...  \n",
       "1  [L AA V EH K IY AH, V EH K IY AH, L AA V EH K ...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_final_trainset(df, num_vowels):\n",
    "    unpacked_dataset1 = pd.DataFrame.from_records(df.VowelPosition.tolist(),columns = range(1,16))\n",
    "    unpacked_dataset2 = pd.DataFrame.from_records(df.ConsonantPosition.tolist(),columns = range(16,31))\n",
    "    unpacked_dataset3 = pd.DataFrame.from_records(df.Occurrence.tolist(),columns = range(31, 70))\n",
    "    \n",
    "    if num_vowels == 2:\n",
    "        unpacked_dataset0 = pd.DataFrame.from_records(df.SyllableCombination.tolist(),columns = ['C12','C2','C1'])\n",
    "        unpacked_dataset4 = pd.DataFrame.from_records(df.VowelsBin.tolist(),columns = range(100,130))\n",
    "        unpacked_dataset5 = pd.DataFrame.from_records(df.PrefixSuffixBin.tolist(),columns = range(1000,1160))\n",
    "    elif num_vowels == 3:\n",
    "        unpacked_dataset0 = pd.DataFrame.from_records(df.SyllableCombination.tolist(),columns = ['C123','C23','C12', 'C3','C2','C1'])\n",
    "        unpacked_dataset4 = pd.DataFrame.from_records(df.VowelsBin.tolist(),columns = range(100,145))\n",
    "        unpacked_dataset5 = pd.DataFrame.from_records(df.PrefixSuffixBin.tolist(),columns = range(1000,1240))\n",
    "    else:\n",
    "        unpacked_dataset0 = pd.DataFrame.from_records(df.SyllableCombination.tolist(),columns = ['C1234','C234','C123','C34','C23','C12','C4','C3','C2','C1'])\n",
    "        unpacked_dataset4 = pd.DataFrame.from_records(df.VowelsBin.tolist(),columns = range(100,160))\n",
    "        unpacked_dataset5 = pd.DataFrame.from_records(df.PrefixSuffixBin.tolist(),columns = range(1000,1320))\n",
    "    final_dataset = pd.concat([df.Target, unpacked_dataset0], axis=1) # Syllable Combinations\n",
    "    final_dataset = pd.concat([final_dataset, unpacked_dataset1], axis=1) # VowelPositionMap\n",
    "    final_dataset = pd.concat([final_dataset, unpacked_dataset2], axis=1) # ConsonantPositionMap\n",
    "    final_dataset = pd.concat([final_dataset, unpacked_dataset3], axis=1) # VectorMap\n",
    "    final_dataset = pd.concat([final_dataset, unpacked_dataset4], axis=1) # VowelMap\n",
    "    final_dataset = pd.concat([final_dataset, unpacked_dataset5], axis=1) # PrefixSuffixMap\n",
    "    \n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Test\n",
    "final2 = get_final_trainset(df2, 2)\n",
    "final3 = get_final_trainset(df3, 3)\n",
    "final4 = get_final_trainset(df4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>C12</th>\n",
       "      <th>C2</th>\n",
       "      <th>C1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "      <th>1154</th>\n",
       "      <th>1155</th>\n",
       "      <th>1156</th>\n",
       "      <th>1157</th>\n",
       "      <th>1158</th>\n",
       "      <th>1159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>K OW EH</td>\n",
       "      <td>EH</td>\n",
       "      <td>K OW</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P ER V Y UW</td>\n",
       "      <td>Y UW</td>\n",
       "      <td>P ER V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          C12    C2      C1  1  2  3  4  5  6  ...   1150  1151  \\\n",
       "0       1      K OW EH    EH    K OW  0  1  1  0  0  0  ...      0     0   \n",
       "1       1  P ER V Y UW  Y UW  P ER V  0  1  0  0  1  0  ...      0     0   \n",
       "\n",
       "   1152  1153  1154  1155  1156  1157  1158  1159  \n",
       "0     0     0     0     0     0     0     0     1  \n",
       "1     0     0     0     0     0     0     0     1  \n",
       "\n",
       "[2 rows x 263 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>C123</th>\n",
       "      <th>C23</th>\n",
       "      <th>C12</th>\n",
       "      <th>C3</th>\n",
       "      <th>C2</th>\n",
       "      <th>C1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>1230</th>\n",
       "      <th>1231</th>\n",
       "      <th>1232</th>\n",
       "      <th>1233</th>\n",
       "      <th>1234</th>\n",
       "      <th>1235</th>\n",
       "      <th>1236</th>\n",
       "      <th>1237</th>\n",
       "      <th>1238</th>\n",
       "      <th>1239</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>D ER AY AH S</td>\n",
       "      <td>AY AH S</td>\n",
       "      <td>D ER AY</td>\n",
       "      <td>AH S</td>\n",
       "      <td>AY</td>\n",
       "      <td>D ER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EH N S IH N JH ER</td>\n",
       "      <td>S IH N JH ER</td>\n",
       "      <td>EH N S IH N</td>\n",
       "      <td>JH ER</td>\n",
       "      <td>S IH N</td>\n",
       "      <td>EH N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target               C123           C23          C12     C3      C2    C1  \\\n",
       "0       2       D ER AY AH S       AY AH S      D ER AY   AH S      AY  D ER   \n",
       "1       1  EH N S IH N JH ER  S IH N JH ER  EH N S IH N  JH ER  S IH N  EH N   \n",
       "\n",
       "   1  2  3  ...   1230  1231  1232  1233  1234  1235  1236  1237  1238  1239  \n",
       "0  0  1  1  ...      1     0     0     0     0     0     0     0     0     0  \n",
       "1  1  0  0  ...      0     0     0     0     0     0     0     0     0     1  \n",
       "\n",
       "[2 rows x 361 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final3[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>C1234</th>\n",
       "      <th>C234</th>\n",
       "      <th>C123</th>\n",
       "      <th>C34</th>\n",
       "      <th>C23</th>\n",
       "      <th>C12</th>\n",
       "      <th>C4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C2</th>\n",
       "      <th>...</th>\n",
       "      <th>1310</th>\n",
       "      <th>1311</th>\n",
       "      <th>1312</th>\n",
       "      <th>1313</th>\n",
       "      <th>1314</th>\n",
       "      <th>1315</th>\n",
       "      <th>1316</th>\n",
       "      <th>1317</th>\n",
       "      <th>1318</th>\n",
       "      <th>1319</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>N AA N P OY Z AH N AH S</td>\n",
       "      <td>P OY Z AH N AH S</td>\n",
       "      <td>N AA N P OY Z AH</td>\n",
       "      <td>Z AH N AH S</td>\n",
       "      <td>P OY Z AH</td>\n",
       "      <td>N AA N P OY</td>\n",
       "      <td>N AH S</td>\n",
       "      <td>Z AH</td>\n",
       "      <td>P OY</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L AA V EH K IY AH</td>\n",
       "      <td>V EH K IY AH</td>\n",
       "      <td>L AA V EH K IY</td>\n",
       "      <td>K IY AH</td>\n",
       "      <td>V EH K IY</td>\n",
       "      <td>L AA V EH</td>\n",
       "      <td>AH</td>\n",
       "      <td>K IY</td>\n",
       "      <td>V EH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                    C1234              C234              C123  \\\n",
       "0       2  N AA N P OY Z AH N AH S  P OY Z AH N AH S  N AA N P OY Z AH   \n",
       "1       2        L AA V EH K IY AH      V EH K IY AH    L AA V EH K IY   \n",
       "\n",
       "           C34        C23          C12      C4    C3    C2  ...  1310  1311  \\\n",
       "0  Z AH N AH S  P OY Z AH  N AA N P OY  N AH S  Z AH  P OY  ...     1     0   \n",
       "1      K IY AH  V EH K IY    L AA V EH      AH  K IY  V EH  ...     0     0   \n",
       "\n",
       "   1312  1313  1314  1315  1316  1317  1318  1319  \n",
       "0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     1  \n",
       "\n",
       "[2 rows x 460 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final4[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_refined_df(test_combination, df, num_vowels):\n",
    "    if num_vowels == 2:\n",
    "        df_features = ['C12','C2','C1']\n",
    "    elif num_vowels == 3:\n",
    "        df_features = ['C123','C23','C12', 'C3','C2','C1']\n",
    "    else:\n",
    "        df_features = ['C1234','C234','C123','C34','C23','C12','C4','C3','C2','C1']\n",
    "    for i in range(len(df_features)):\n",
    "        sub_df = df[df[df_features[i]].str.contains('^' + test_combination[i] + '$')]\n",
    "        if sub_df.shape[0] > 0:\n",
    "            return sub_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>C12</th>\n",
       "      <th>C2</th>\n",
       "      <th>C1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "      <th>1154</th>\n",
       "      <th>1155</th>\n",
       "      <th>1156</th>\n",
       "      <th>1157</th>\n",
       "      <th>1158</th>\n",
       "      <th>1159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P ER V Y UW</td>\n",
       "      <td>Y UW</td>\n",
       "      <td>P ER V</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          C12    C2      C1  1  2  3  4  5  6  ...   1150  1151  \\\n",
       "1       1  P ER V Y UW  Y UW  P ER V  0  1  0  0  1  0  ...      0     0   \n",
       "\n",
       "   1152  1153  1154  1155  1156  1157  1158  1159  \n",
       "1     0     0     0     0     0     0     0     1  \n",
       "\n",
       "[1 rows x 263 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test\n",
    "get_refined_df(['P ER V Y UW', 'Y UW', 'P ER V'], final2, num_vowels = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, classifier_file):\n",
    "    # put code here #\n",
    "    vowel = {'AA': 0, 'AW': 1, 'AY': 2, 'ER': 3, 'EY': 4, 'IY': 5, 'OW': 6, 'OY': 7, 'UW': 8, 'AE': 9, 'AH': 10, 'AO': 11, 'EH': 12, 'IH': 13, 'UH': 14}\n",
    "    consonant = {'AA': 0, 'AW': 1, 'AY': 2, 'ER': 3, 'EY': 4, 'IY': 5, 'OW': 6, 'OY': 7, 'UW': 8, 'AE': 9, 'AH': 10, 'AO': 11, 'EH': 12, 'IH': 13, 'UH': 14, 'P': 15, 'B': 16, 'CH': 17, 'D': 18, 'DH': 19, 'F': 20, 'G': 21, 'HH': 22, 'JH': 23, 'K': 24, 'L': 25, 'M': 26, 'N': 27, 'NG': 28, 'R': 29, 'S': 30, 'SH': 31, 'T': 32, 'TH': 33, 'V': 34, 'W': 35, 'Y': 36, 'Z': 37, 'ZH': 38}\n",
    "    \n",
    "    vowel2, vowel3, vowel4 = get_splitted_data(data, vowel, consonant)\n",
    "    df2 = get_df(vowel2, vowel, consonant)\n",
    "    df3 = get_df(vowel3, vowel, consonant)\n",
    "    df4 = get_df(vowel4, vowel, consonant)\n",
    "    final2 = get_final_trainset(df2, 2)\n",
    "    final3 = get_final_trainset(df3, 3)\n",
    "    final4 = get_final_trainset(df4, 4)\n",
    "    \n",
    "    file = open(classifier_file, 'wb')\n",
    "    pickle.dump(vowel, file)\n",
    "    pickle.dump(consonant, file)\n",
    "    pickle.dump(final2, file)\n",
    "    pickle.dump(final3, file)\n",
    "    pickle.dump(final4, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27622, 263)\n",
      "(15389, 361)\n",
      "(4889, 460)\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "final2, final3, final4 = train(raw_data, ' ')\n",
    "print(final2.shape)\n",
    "print(final3.shape)\n",
    "print(final4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(data, classifier_file):\n",
    "\n",
    "    # load the model\n",
    "    file = open(classifier_file, 'rb')\n",
    "    pickle.dump(vowel, file)\n",
    "    pickle.dump(consonant, file)\n",
    "    pickle.dump(train2, file)\n",
    "    pickle.dump(train3, file)\n",
    "    pickle.dump(train4, file)\n",
    "    file.close()\n",
    "    \n",
    "    prediction = []\n",
    "    for curr_test in data[:]:\n",
    "        word, removed_stress = split_to_list(curr_row)\n",
    "        word, removed_stress = combined_filter(word, removed_stress, vowel)\n",
    "        \n",
    "        if word == 1 or removed_stress == [1]:\n",
    "            prediction.append(1)\n",
    "            continue\n",
    "        \n",
    "        num_vowel = count_vowel(removed_stress, vowel)\n",
    "        \n",
    "        if num_vowel <= 1:\n",
    "            prediction.append(1)\n",
    "            continue\n",
    "        \n",
    "        elif num_vowel == 2:\n",
    "            vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(removed_stress, vowel, consonant)\n",
    "            prefix_suffix = get_prefix_and_suffix(vowel_positions, removed_stress, consonant)\n",
    "            syllables = split_structure_vowel2(vowel_positions, removed_stress)\n",
    "            VowelsBin = vowels_to_bin(vowels, vowel)\n",
    "            PrefixSuffixBin = prefix_suffix_to_bin(prefix_suffix, consonant)\n",
    "            SyllableCombination = get_combination(syllables)\n",
    "            \n",
    "            refined_df = get_refined_df(SyllableCombination, train2, 2)\n",
    "            features = refined_df[4:]\n",
    "            train_X = refined_df[features]\n",
    "            train_y = refined_df['Target']\n",
    "            test_X = SyllableCombination + VowelMap + ConsonantMap + VectorMap + VowelsBin + SyllableCombination\n",
    "            \n",
    "            if refined_df.shape[0] < 6:\n",
    "                neigh = KNeighborsClassifier(n_neighbors = train_X.shape[0], weights = 'distance')\n",
    "            else:\n",
    "                neigh = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "            neigh.fit(train_X, train_y)\n",
    "            curr_pred = neigh.predict(test_X)[0]\n",
    "            prediction.append(curr_pred) \n",
    "            \n",
    "        elif num_vowel == 3:\n",
    "            vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(removed_stress, vowel, consonant)\n",
    "            prefix_suffix = get_prefix_and_suffix(vowel_positions, removed_stress, consonant)\n",
    "            syllables = split_structure_vowel3(vowel_positions, removed_stress)\n",
    "            VowelsBin = vowels_to_bin(vowels, vowel)\n",
    "            PrefixSuffixBin = prefix_suffix_to_bin(prefix_suffix, consonant)\n",
    "            SyllableCombination = get_combination(syllables)\n",
    "            \n",
    "            refined_df = get_refined_df(SyllableCombination, train3, 3)\n",
    "            features = refined_df[7:]\n",
    "            train_X = refined_df[features]\n",
    "            train_y = refined_df['Target']\n",
    "            test_X = SyllableCombination + VowelMap + ConsonantMap + VectorMap + VowelsBin + SyllableCombination\n",
    "            \n",
    "            if refined_df.shape[0] < 6:\n",
    "                neigh = KNeighborsClassifier(n_neighbors = train_X.shape[0], weights = 'distance')\n",
    "            else:\n",
    "                neigh = KNeighborsClassifier(n_neighbors = 6, weights = 'distance')\n",
    "            neigh.fit(train_X, train_y)\n",
    "            curr_pred = neigh.predict(test_X)[0]\n",
    "            prediction.append(curr_pred)\n",
    "            \n",
    "        else:\n",
    "            vowels, vowel_positions, structure, VowelMap, ConsonantMap, VectorMap = get_structure_and_vowels(removed_stress, vowel, consonant)\n",
    "            prefix_suffix = get_prefix_and_suffix(vowel_positions, removed_stress, consonant)\n",
    "            syllables = split_structure_vowel4(vowel_positions, removed_stress)\n",
    "            VowelsBin = vowels_to_bin(vowels, vowel)\n",
    "            PrefixSuffixBin = prefix_suffix_to_bin(prefix_suffix, consonant)\n",
    "            SyllableCombination = get_combination(syllables)\n",
    "            \n",
    "            refined_df = get_refined_df(SyllableCombination, train4, 4)\n",
    "            features = refined_df[11:]\n",
    "            train_X = refined_df[features]\n",
    "            train_y = refined_df['Target']\n",
    "            test_X = SyllableCombination + VowelMap + ConsonantMap + VectorMap + VowelsBin + SyllableCombination\n",
    "            \n",
    "            if refined_df.shape[0] < 13:\n",
    "                neigh = KNeighborsClassifier(n_neighbors = train_X.shape[0], weights = 'distance')\n",
    "            else:\n",
    "                neigh = KNeighborsClassifier(n_neighbors = 13, weights = 'distance')\n",
    "            neigh.fit(train_X, train_y)\n",
    "            curr_pred = neigh.predict(test_X)[0]\n",
    "            prediction.append(curr_pred)\n",
    "    \n",
    "    return prediction\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
